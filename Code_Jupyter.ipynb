{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c23652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from cleantext import clean\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "409b9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(input_text, regex_filter):\n",
    "    cleaned_text = re.sub(r'(\\S+\\.com*\\S+)', '<url>', input_text)\n",
    "    cleaned_text = re.sub(r'(\\S+\\.net*\\S+)', '<url>', cleaned_text)\n",
    "    cleaned_text = clean(cleaned_text,  # does not remove special characters such as < , ^ etc.\n",
    "        normalize_whitespace=True,\n",
    "        fix_unicode=True,  # fix various unicode errors\n",
    "        to_ascii=True,  # transliterate to closest ASCII representation\n",
    "        lower=True,  # lowercase text\n",
    "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,  # replace all URLs with a special token\n",
    "        no_emails=True,  # replace all email addresses with a special token\n",
    "        no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "        no_numbers=True,  # replace all numbers with a special token\n",
    "        no_digits=True,  # replace all digits with a special token\n",
    "        no_currency_symbols=True,  # replace all currency symbols with a special token\n",
    "        no_punct=True,  # remove punctuations\n",
    "        no_emoji=True,\n",
    "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_phone_number=\"<PHONE>\",\n",
    "        replace_with_number=\"<NUMBER>\",\n",
    "        replace_with_digit=\"<DIGIT>\",\n",
    "        replace_with_currency_symbol=\"<CUR>\",\n",
    "        lang=\"en\")\n",
    "\n",
    "    word_filter_list = []\n",
    "\n",
    "    for i in regex_filter:\n",
    "        words = re.findall(i, cleaned_text)\n",
    "        word_filter_list.append((i, len(words)))\n",
    "\n",
    "    for i in word_filter_list:\n",
    "        cleaned_text = re.sub(i[0], '', cleaned_text)\n",
    "        cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    stemmed_and_filtered = [ps.stem(w) for w in word_tokenize(cleaned_text) if w not in stop_words]\n",
    "\n",
    "    return stemmed_and_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee537ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_21188\\3710294571.py:6: DtypeWarning: Columns (10,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('news_cleaned_2018_02_13.csv', encoding='utf8', nrows=2_500_000, chunksize=100_000, lineterminator='\\n', dtype={'content':'string', 'type':'string'}):\n",
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_21188\\3710294571.py:6: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv('news_cleaned_2018_02_13.csv', encoding='utf8', nrows=2_500_000, chunksize=100_000, lineterminator='\\n', dtype={'content':'string', 'type':'string'}):\n"
     ]
    }
   ],
   "source": [
    "end_result = []\n",
    "def clean_and_store(row):\n",
    "    data_new = clean_data(row['content'], ['<url>', '<email>', '<phone>', '<number>', '<digit>', '<cur>'])\n",
    "    end_result.append([' '.join(data_new), row['type']])\n",
    "\n",
    "for chunk in pd.read_csv('news_cleaned_2018_02_13.csv', encoding='utf8', nrows=2_500_000, chunksize=100_000, lineterminator='\\n', dtype={'content':'string', 'type':'string'}):\n",
    "    cleaned_row_chunk = chunk.apply(clean_and_store, axis = 1).dropna()\n",
    "\n",
    "df_processed_end_results = pd.DataFrame(end_result, columns=['articles', 'type'])\n",
    "df_processed_end_results.to_csv('new_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7672ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed_cleaned = pd.read_csv('new_processed.csv', encoding='utf8', lineterminator='\\n', dtype={'artikler':'string', 'type':'string'}, nrows = 1_500_000)\n",
    "# df_processed_cleaned.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3390101e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artikler    object\n",
      "type        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# X = df_processed_end_results['articles']\n",
    "\n",
    "# for i, x in enumerate(X):\n",
    "#     if not isinstance(x, str):\n",
    "#         print(f\"Element {i} is not a string: {x}\")\n",
    "        \n",
    "# print(df_processed_cleaned.loc[110130, 'articles'])\n",
    "# vectorizer = CountVectorizer() #Counts and vectorizes\n",
    "# X = vectorizer.fit_transform(X)\n",
    "\n",
    "# y = df_processed_cleaned['type']\n",
    "# encoder = LabelEncoder() #Good for binary use, and sets fake as 0 and reliable as 1\n",
    "# y = encoder.fit_transform(y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "# #Baseline models\n",
    "# DecisionTree = DecisionTreeClassifier()\n",
    "# LogisticRegression = LogisticRegression(max_iter=1000)\n",
    "# LinearRegression = LinearRegression()\n",
    "\n",
    "# DecisionTree.fit(X_train, y_train)\n",
    "# LogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_decision = DecisionTree.predict(X_test)\n",
    "# y_pred_logistic = LogisticRegression.predict(X_test)\n",
    "\n",
    "# acc_decision = accuracy_score(y_test, y_pred_decision)\n",
    "# acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "\n",
    "# print(acc_decision)\n",
    "# print(acc_logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
