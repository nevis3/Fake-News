{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c23652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from cleantext import clean\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409b9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(input_text, regex_filter):\n",
    "    cleaned_text = re.sub(r'(\\S+\\.com*\\S+)', '<url>', input_text)\n",
    "    cleaned_text = re.sub(r'(\\S+\\.net*\\S+)', '<url>', cleaned_text)\n",
    "    cleaned_text = clean(cleaned_text,  # does not remove special characters such as < , ^ etc.\n",
    "        normalize_whitespace=True,\n",
    "        fix_unicode=True,  # fix various unicode errors\n",
    "        to_ascii=True,  # transliterate to closest ASCII representation\n",
    "        lower=True,  # lowercase text\n",
    "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,  # replace all URLs with a special token\n",
    "        no_emails=True,  # replace all email addresses with a special token\n",
    "        no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "        no_numbers=True,  # replace all numbers with a special token\n",
    "        no_digits=True,  # replace all digits with a special token\n",
    "        no_currency_symbols=True,  # replace all currency symbols with a special token\n",
    "        no_punct=True,  # remove punctuations\n",
    "        no_emoji=True,\n",
    "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_phone_number=\"<PHONE>\",\n",
    "        replace_with_number=\"<NUMBER>\",\n",
    "        replace_with_digit=\"<DIGIT>\",\n",
    "        replace_with_currency_symbol=\"<CUR>\",\n",
    "        lang=\"en\")\n",
    "\n",
    "    word_filter_list = []\n",
    "\n",
    "    for i in regex_filter:\n",
    "        words = re.findall(i, cleaned_text)\n",
    "        word_filter_list.append((i, len(words)))\n",
    "\n",
    "    for i in word_filter_list:\n",
    "        cleaned_text = re.sub(i[0], '', cleaned_text)\n",
    "        cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    stemmed_and_filtered = [ps.stem(w) for w in word_tokenize(cleaned_text) if w not in stop_words]\n",
    "\n",
    "    return stemmed_and_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee537ca2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m     end_result\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(data_new), row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnews_cleaned_2018_02_13.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf8\u001B[39m\u001B[38;5;124m'\u001B[39m, nrows\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2_500_000\u001B[39m, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100_000\u001B[39m, lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstring\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstring\u001B[39m\u001B[38;5;124m'\u001B[39m}):\n\u001B[1;32m----> 7\u001B[0m     cleaned_row_chunk \u001B[38;5;241m=\u001B[39m \u001B[43mchunk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclean_and_store\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdropna()\n\u001B[0;32m      9\u001B[0m df_processed_end_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(end_result, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124marticles\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     10\u001B[0m df_processed_end_results\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnew_processed.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9557\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m   9559\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m   9560\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   9561\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   9566\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m   9567\u001B[0m )\n\u001B[1;32m-> 9568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\pandas\\core\\apply.py:764\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[1;32m--> 764\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\pandas\\core\\apply.py:891\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 891\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    893\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\pandas\\core\\apply.py:907\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    904\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    905\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m    906\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m--> 907\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    908\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m    909\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m    910\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m    911\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m, in \u001B[0;36mclean_and_store\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclean_and_store\u001B[39m(row):\n\u001B[1;32m----> 3\u001B[0m     data_new \u001B[38;5;241m=\u001B[39m \u001B[43mclean_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<url>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<email>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<phone>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<number>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<digit>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m<cur>\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     end_result\u001B[38;5;241m.\u001B[39mappend([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(data_new), row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n",
      "Cell \u001B[1;32mIn[7], line 38\u001B[0m, in \u001B[0;36mclean_data\u001B[1;34m(input_text, regex_filter)\u001B[0m\n\u001B[0;32m     35\u001B[0m     cleaned_text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(i[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, cleaned_text)\n\u001B[0;32m     36\u001B[0m     cleaned_text \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m +\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, cleaned_text)\n\u001B[1;32m---> 38\u001B[0m stop_words \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[43mstopwords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwords\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43menglish\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     39\u001B[0m ps \u001B[38;5;241m=\u001B[39m PorterStemmer()\n\u001B[0;32m     41\u001B[0m stemmed_and_filtered \u001B[38;5;241m=\u001B[39m [ps\u001B[38;5;241m.\u001B[39mstem(w) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m word_tokenize(cleaned_text) \u001B[38;5;28;01mif\u001B[39;00m w \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m stop_words]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001B[0m, in \u001B[0;36mWordListCorpusReader.words\u001B[1;34m(self, fileids, ignore_lines_startswith)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwords\u001B[39m(\u001B[38;5;28mself\u001B[39m, fileids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, ignore_lines_startswith\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m     20\u001B[0m         line\n\u001B[1;32m---> 21\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m line_tokenize(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfileids\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     22\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line\u001B[38;5;241m.\u001B[39mstartswith(ignore_lines_startswith)\n\u001B[0;32m     23\u001B[0m     ]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001B[0m, in \u001B[0;36mCorpusReader.raw\u001B[1;34m(self, fileids)\u001B[0m\n\u001B[0;32m    216\u001B[0m contents \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    217\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fileids:\n\u001B[1;32m--> 218\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[0;32m    219\u001B[0m         contents\u001B[38;5;241m.\u001B[39mappend(fp\u001B[38;5;241m.\u001B[39mread())\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concat(contents)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001B[0m, in \u001B[0;36mCorpusReader.open\u001B[1;34m(self, file)\u001B[0m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;124;03mReturn an open stream that can be used to read the given file.\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;124;03mIf the file's encoding is not None, then the stream will\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;124;03m:param file: The file identifier of the file to read.\u001B[39;00m\n\u001B[0;32m    229\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    230\u001B[0m encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding(file)\n\u001B[1;32m--> 231\u001B[0m stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_root\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mopen(encoding)\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m stream\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\data.py:334\u001B[0m, in \u001B[0;36mFileSystemPathPointer.join\u001B[1;34m(self, fileid)\u001B[0m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mjoin\u001B[39m(\u001B[38;5;28mself\u001B[39m, fileid):\n\u001B[0;32m    333\u001B[0m     _path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path, fileid)\n\u001B[1;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mFileSystemPathPointer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\compat.py:41\u001B[0m, in \u001B[0;36mpy3_data.<locals>._decorator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decorator\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     40\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args[\u001B[38;5;241m0\u001B[39m], add_py3_data(args[\u001B[38;5;241m1\u001B[39m])) \u001B[38;5;241m+\u001B[39m args[\u001B[38;5;241m2\u001B[39m:]\n\u001B[1;32m---> 41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m init_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\site-packages\\nltk\\data.py:311\u001B[0m, in \u001B[0;36mFileSystemPathPointer.__init__\u001B[1;34m(self, _path)\u001B[0m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;124;03mCreate a new path pointer for the given absolute path.\u001B[39;00m\n\u001B[0;32m    306\u001B[0m \n\u001B[0;32m    307\u001B[0m \u001B[38;5;124;03m:raise IOError: If the given path does not exist.\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    310\u001B[0m _path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mabspath(_path)\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexists\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_path\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo such file or directory: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m _path)\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m _path\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\Fake-News-Prediction-Model\\lib\\genericpath.py:19\u001B[0m, in \u001B[0;36mexists\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 19\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "end_result = []\n",
    "def clean_and_store(row):\n",
    "    data_new = clean_data(row['content'], ['<url>', '<email>', '<phone>', '<number>', '<digit>', '<cur>'])\n",
    "    end_result.append([' '.join(data_new), row['type']])\n",
    "\n",
    "for chunk in pd.read_csv('news_cleaned_2018_02_13.csv', encoding='utf8', nrows=2_500_000, chunksize=100_000, lineterminator='\\n', dtype={'content':'string', 'type':'string'}):\n",
    "    cleaned_row_chunk = chunk.apply(clean_and_store, axis = 1).dropna()\n",
    "\n",
    "df_processed_end_results = pd.DataFrame(end_result, columns=['articles', 'type'])\n",
    "df_processed_end_results.to_csv('new_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7672ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_processed_cleaned = pd.read_csv('new_processed.csv', encoding='utf8', lineterminator='\\n', dtype={'artikler':'string', 'type':'string'}, nrows = 1_500_000)\n",
    "# df_processed_cleaned.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3390101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = df_processed_end_results['articles']\n",
    "\n",
    "# for i, x in enumerate(X):\n",
    "#     if not isinstance(x, str):\n",
    "#         print(f\"Element {i} is not a string: {x}\")\n",
    "        \n",
    "# print(df_processed_cleaned.loc[110130, 'articles'])\n",
    "# vectorizer = CountVectorizer() #Counts and vectorizes\n",
    "# X = vectorizer.fit_transform(X)\n",
    "\n",
    "# y = df_processed_cleaned['type']\n",
    "# encoder = LabelEncoder() #Good for binary use, and sets fake as 0 and reliable as 1\n",
    "# y = encoder.fit_transform(y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "\n",
    "# #Baseline models\n",
    "# DecisionTree = DecisionTreeClassifier()\n",
    "# LogisticRegression = LogisticRegression(max_iter=1000)\n",
    "# LinearRegression = LinearRegression()\n",
    "\n",
    "# DecisionTree.fit(X_train, y_train)\n",
    "# LogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_decision = DecisionTree.predict(X_test)\n",
    "# y_pred_logistic = LogisticRegression.predict(X_test)\n",
    "\n",
    "# acc_decision = accuracy_score(y_test, y_pred_decision)\n",
    "# acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "\n",
    "# print(acc_decision)\n",
    "# print(acc_logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
