{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c23652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from cleantext import clean\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409b9efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(input_text, regex_filter):\n",
    "    cleaned_text = re.sub(r'(\\S+\\.com*\\S+)', '<url>', input_text)\n",
    "    cleaned_text = re.sub(r'(\\S+\\.net*\\S+)', '<url>', cleaned_text)\n",
    "    cleaned_text = clean(cleaned_text,  # does not remove special characters such as < , ^ etc.\n",
    "        normalize_whitespace=True,\n",
    "        fix_unicode=True,  # fix various unicode errors\n",
    "        to_ascii=True,  # transliterate to closest ASCII representation\n",
    "        lower=True,  # lowercase text\n",
    "        no_line_breaks=True,  # fully strip line breaks as opposed to only normalizing them\n",
    "        no_urls=True,  # replace all URLs with a special token\n",
    "        no_emails=True,  # replace all email addresses with a special token\n",
    "        no_phone_numbers=True,  # replace all phone numbers with a special token\n",
    "        no_numbers=True,  # replace all numbers with a special token\n",
    "        no_digits=True,  # replace all digits with a special token\n",
    "        no_currency_symbols=True,  # replace all currency symbols with a special token\n",
    "        no_punct=True,  # remove punctuations\n",
    "        no_emoji=True,\n",
    "        replace_with_punct=\"\",  # instead of removing punctuations you may replace them\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_phone_number=\"<PHONE>\",\n",
    "        replace_with_number=\"<NUMBER>\",\n",
    "        replace_with_digit=\"<DIGIT>\",\n",
    "        replace_with_currency_symbol=\"<CUR>\",\n",
    "        lang=\"en\")\n",
    "\n",
    "    word_filter_list = []\n",
    "\n",
    "    for i in regex_filter:\n",
    "        words = re.findall(i, cleaned_text)\n",
    "        word_filter_list.append((i, len(words)))\n",
    "\n",
    "    for i in word_filter_list:\n",
    "        cleaned_text = re.sub(i[0], '', cleaned_text)\n",
    "        cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    stemmed_and_filtered = [ps.stem(w) for w in word_tokenize(cleaned_text) if w not in stop_words]\n",
    "\n",
    "    return stemmed_and_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cda1fd96",
   "metadata": {},
   "source": [
    "DO NOT RUN THE CODE BELOW! ONLY RUN THIS ONCE (ALREADY DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee537ca2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Method to only clean the data and keep the types intact\n",
    "# THIS CODE SHOULD ONLY BE RUN ONCE, AS IT TAKES A LONG TIME\n",
    "end_result = []\n",
    "def clean_and_store(row):\n",
    "    data_new = clean_data(row['content'], ['<url>', '<email>', '<phone>', '<number>', '<digit>', '<cur>'])\n",
    "    end_result.append([' '.join(data_new), row['type']])\n",
    "\n",
    "#Take it in chunk to not overload memory\n",
    "for chunk in pd.read_csv('news_cleaned_2018_02_13.csv', encoding='utf8', nrows=2_500_000, chunksize=100_000, lineterminator='\\n', dtype={'content':'string', 'type':'string'}):\n",
    "    chunk.apply(clean_and_store, axis = 1).dropna()\n",
    "\n",
    "#Save the end result and remove nan rows\n",
    "df_processed_end_results = pd.DataFrame(end_result, columns=['articles', 'type'])\n",
    "df_processed_end_results.dropna(subset=['articles'], inplace=True) #Removes nan articles\n",
    "df_processed_end_results.to_csv('new_processed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed26a01f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Also changes the type\n",
    "df_cleaned = pd.read_csv('new_processed.csv', encoding='utf8', lineterminator='\\n', dtype={'content':'string', 'type':'string'})\n",
    "df_cleaned.columns = df_cleaned.columns.str.strip() #Remove unecessary \\r\n",
    "df_cleaned['type'] = df_cleaned['type'].replace('\\r', '', regex=True) #Remove unecessary r from types\n",
    "\n",
    "type_change = {'unreliable' : 'fake', 'bias' : 'fake', 'clickbait' : 'fake', 'junksci' : 'fake', 'political' : 'fake', 'conspiracy' : 'fake', 'hate' : 'fake', 'rumor' : 'fake', 'satire' : 'fake'}\n",
    "df_cleaned.loc[df_cleaned['type'].isin(type_change.keys()), 'type'] = df_cleaned['type'].map(type_change) #Maps the dict and changes values\n",
    "df_cleaned = df_cleaned[~df_cleaned['type'].isin(['nan', 'unknown'])] #Removes these rows directly\n",
    "\n",
    "df_cleaned.to_csv('new_processed_type.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390101e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned_and_changed = pd.read_csv('new_processed_type.csv', encoding='utf8', lineterminator='\\n', dtype={'content':'string', 'type':'string'})\n",
    "df_cleaned_and_changed.columns = df_cleaned.columns.str.strip() #Remove unecessary \\r\n",
    "df_cleaned_and_changed['type'] = df_cleaned['type'].replace('\\r', '', regex=True) #Remove unecessary r from types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b743865",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X = df_cleaned_and_changed['articles']\n",
    "vectorizer = CountVectorizer() #Counts and vectorizes\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "y = df_cleaned_and_changed['type']\n",
    "encoder = LabelEncoder() #Good for binary use, and sets fake as 0 and reliable as 1\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61d373",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Baseline models\n",
    "DecisionTree = DecisionTreeClassifier()\n",
    "LogisticReg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "DecisionTree.fit(X_train, y_train)\n",
    "LogisticReg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_decision = DecisionTree.predict(X_test)\n",
    "y_pred_logistic = LogisticReg.predict(X_test)\n",
    "\n",
    "acc_decision = accuracy_score(y_test, y_pred_decision)\n",
    "acc_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "\n",
    "print(acc_decision)\n",
    "print(acc_logistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
